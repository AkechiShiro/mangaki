{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.sparse import csc_matrix\n",
    "from numpy.random import choice\n",
    "from mangaki.utils.values import rating_values\n",
    "from mangaki.models import Rating\n",
    "import pandas\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_matrix(fname=None):\n",
    "    user_list, item_list, data = [],[], []\n",
    "\n",
    "\n",
    "    if fname is None:\n",
    "        content = Rating.objects.values_list('user_id',\n",
    "                                             'work_id',\n",
    "                                             'choice')\n",
    "        for user_id, item_id, choice in content:\n",
    "            user_list.append(user_id)\n",
    "            item_list.append(item_id)\n",
    "            data.append(rating_values[choice])\n",
    "    else:\n",
    "        content = pandas.read_csv(fname,\n",
    "                                  header=None).as_matrix()\n",
    "        for user_id, item_id, choice in content:\n",
    "            user_list.append(user_id)\n",
    "            item_list.append(item_id)\n",
    "            data.append(rating_values[choice])\n",
    "        \n",
    "    user_set=set(user_list)\n",
    "    item_set=set(item_list)\n",
    "    user_dict = {v: k for k, v in enumerate(user_set)}\n",
    "    item_dict = {v: k for k, v in enumerate(item_set)}\n",
    "    row=[user_dict[v] for v in user_list]\n",
    "    col=[item_dict[v] for v in item_list]\n",
    "    matrix = csc_matrix((data, (row, col)), shape=(len(user_set),len(item_set))).toarray()\n",
    "    return matrix, user_dict, item_dict, user_set, item_set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#build_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fonctions permettant de calculer des diamètres\n",
    "#à appeler ds compare : diameter_0(nb_points, sampled_items) et pareil pr uniform_itemss\n",
    "#@requires : svd.VT ou alors le changer par matrix ....\n",
    "\n",
    "def diameter(r, matrix, nb_points, items):\n",
    "    return ((2/(nb_points*(nb_points-1))*((pdist(matrix[:, items].T)**r).sum()))**(1/r)) \n",
    "\n",
    "def diameter_0(nb_points,matrix, items):\n",
    "    r=1\n",
    "    premier=diameter(r, matrix, 10, items)\n",
    "    deuxième=diameter(r/2,matrix, 10, items)\n",
    "    while premier-deuxième >0.01*deuxième :\n",
    "        premier=diameter(r, matrix, 10, items)\n",
    "        r=r/2\n",
    "        deuxième=diameter(r,matrix, 10, items)\n",
    "    return deuxième"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimilarityMatrix(object):\n",
    "  \n",
    "    def __init__(self, nb_components_svd=10, fname=None, algo='svd', metric='cosine'):\n",
    "        self.nb_components_svd = nb_components_svd\n",
    "        self.algo = algo\n",
    "        self.matrix,  self.user_dict, self.item_dict, self.user_set, self.item_set = self.build_matrix(fname)\n",
    "        self.similarity_matrix = self.make_similarity_matrix('cosine')\n",
    "        \n",
    "\n",
    "    def build_matrix(self, fname=None):\n",
    "        user_list, item_list, data = [],[], []\n",
    "\n",
    "\n",
    "        if fname is None:\n",
    "            content = Rating.objects.values_list('user_id',\n",
    "                                             'work_id',\n",
    "                                             'choice')\n",
    "            for user_id, item_id, choice in content:\n",
    "                user_list.append(user_id)\n",
    "                item_list.append(item_id)\n",
    "                data.append(rating_values[choice])\n",
    "        else:\n",
    "            content = pandas.read_csv(fname,\n",
    "                                  header=None).as_matrix()\n",
    "            for user_id, item_id, choice in content:\n",
    "                user_list.append(user_id)\n",
    "                item_list.append(item_id)\n",
    "                data.append(rating_values[choice])\n",
    "        \n",
    "        user_set=set(user_list)\n",
    "        item_set=set(item_list)\n",
    "        user_dict = {v: k for k, v in enumerate(user_set)}\n",
    "        item_dict = {v: k for k, v in enumerate(item_set)}\n",
    "        row = [user_dict[v] for v in user_list]\n",
    "        col = [item_dict[v] for v in item_list]\n",
    "        matrix = csc_matrix((data, (row, col)), shape=(len(user_set),len(item_set))).toarray()\n",
    "        return matrix, user_dict, item_dict, user_set, item_set\n",
    "    \n",
    "    def make_svd_matrix(self, matrix):\n",
    "        self.U, self.sigma, self.VT = randomized_svd(matrix, self.nb_components_svd)\n",
    "        \n",
    "    def make_similarity_matrix(self, option):\n",
    "        if self.algo == 'svd':\n",
    "            self.make_svd_matrix(self.matrix)\n",
    "            return 1 - squareform(pdist(self.matrix.T, metric=option))\n",
    "        return 1 - squareform(pdist(self.matrix.T, metric=option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.00399629,  0.        , ...,  0.        ,\n",
       "         0.33209032, -0.66592716],\n",
       "       [ 0.00399629,  1.        ,  0.46429041, ...,  0.13710028,\n",
       "         0.16854555,  0.05921259],\n",
       "       [ 0.        ,  0.46429041,  1.        , ...,  0.14765262,\n",
       "         0.12200171,  0.12325628],\n",
       "       ..., \n",
       "       [ 0.        ,  0.13710028,  0.14765262, ...,  1.        ,\n",
       "        -0.23250973,  0.13987268],\n",
       "       [ 0.33209032,  0.16854555,  0.12200171, ..., -0.23250973,\n",
       "         1.        , -0.22059509],\n",
       "       [-0.66592716,  0.05921259,  0.12325628, ...,  0.13987268,\n",
       "        -0.22059509,  1.        ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity=SimilarityMatrix()\n",
    "similarity.matrix\n",
    "similarity.similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MangakiUniform(object):\n",
    "\n",
    "    #def __init__(self, nb_points):\n",
    "    #    self.nb_points = nb_points\n",
    "\n",
    "    def sample_k(self, matrix_similarity, nb_points, items):\n",
    "        uniform_items = items\n",
    "        \n",
    "        return choice(items, nb_points).tolist()\n",
    "\n",
    "    #def __str__(self):\n",
    "    #    return 'uniform list, nb_points=%d' % self.nb_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MangakiDPP(object):\n",
    "\n",
    "    #def __init__(self, similarity):\n",
    "    #    self.similarity = similarity\n",
    "\n",
    "    def sample_k(self, L, k, items, max_nb_iterations=1000, rng=np.random):\n",
    "        \"\"\"\n",
    "        Thanks to mehdidc on github : https://github.com/mehdidc/dpp\n",
    "        Sample a list of k items from a DPP defined\n",
    "        by the similarity matrix L. The algorithm\n",
    "        is iterative and runs for max_nb_iterations.\n",
    "        The algorithm used is from\n",
    "        (Fast Determinantal Point Process Sampling withw\n",
    "        Application to Clustering, Byungkon Kang, NIPS 2013)\n",
    "        \"\"\"\n",
    "        #self.similarity.build_matrix()\n",
    "        #L = self.similarity.make_similarity_matrix('cosine')\n",
    "        #items = list(self.similarity.user_set)\n",
    "        initial = rng.choice(range(len(items)), size=k, replace=False)\n",
    "        X = [False] * len(items)\n",
    "        for i in initial:\n",
    "            X[i] = True\n",
    "        X = np.array(X)\n",
    "        for i in range(max_nb_iterations):\n",
    "            u = rng.choice(np.arange(len(items))[X])\n",
    "            v = rng.choice(np.arange(len(items))[~X])\n",
    "            Y = X.copy()\n",
    "            Y[u] = False\n",
    "            L_Y = L[Y, :]\n",
    "            L_Y = L_Y[:, Y]\n",
    "            L_Y_inv = np.linalg.inv(L_Y)\n",
    "            c_v = L[v:v+1, :]\n",
    "            c_v = c_v[:, v:v+1]\n",
    "            b_v = L[Y, :]\n",
    "            b_v = b_v[:, v:v+1]\n",
    "            c_u = L[u:u+1, :]\n",
    "            c_u = c_u[:, u:u+1]\n",
    "            b_u = L[Y, :]\n",
    "            b_u = b_u[:, u:u+1]\n",
    "            p = min(1, c_v - np.dot(np.dot(b_v.T, L_Y_inv), b_v) /\n",
    "                    (c_u - np.dot(np.dot(b_u.T, L_Y_inv.T), b_u)))\n",
    "            if rng.uniform() <= p:\n",
    "                X = Y[:]\n",
    "                X[v] = True\n",
    "        return np.array(items)[X]\n",
    "\n",
    "    #def __str__(self):\n",
    "    #    return 'sample dpp list, nb_points=%d' % self.nb_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "\"\"\"\n",
    " Il faudrait que compare prenne une liste d'objets\n",
    "(MangakiUniform / MangakiDPP / autres si on en créé\n",
    "plus tard) et les compare entre eux en samplant le\n",
    "même nombre de points etc\n",
    "voir mangaki/mangaki/mangaki/management.compare.py\n",
    "\n",
    "\"\"\"\n",
    "#algos est une liste contenant un objet de MangakiDPP et un de MangakiUniform pr l'instant : dpp le 1er, uniform le 2ème\n",
    "def compare2(similarity_matrix, algos, nb_points, nb_iterations=100):\n",
    "\n",
    "    sum_det_uni, sum_diam_uni, sum_det_dpp, sum_diam_dpp = 0, 0, 0, 0\n",
    "    similarity = SimilarityMatrix()\n",
    "    indicateur = 0\n",
    "    pb = 0\n",
    "    dpp = algos[0]\n",
    "    uniform = algos[1]\n",
    "    items = list(similarity.user_set)\n",
    "    while indicateur != nb_iterations:\n",
    "        try:\n",
    "            sampled_items = dpp.sample_k(similarity.similarity_matrix, nb_points, items)\n",
    "        except np.linalg.linalg.LinAlgError as err:\n",
    "            pb = 1\n",
    "        if pb == 0:\n",
    "            indicateur = indicateur+1\n",
    "            uniform_items = uniform.sample_k(similarity.similarity_matrix, nb_points, items)\n",
    "            det_uni = np.linalg.det(squareform(pdist(\n",
    "                       similarity.matrix[:, uniform_items].T,\n",
    "                       metric='cosine')))\n",
    "            det_dpp = np.linalg.det(squareform(pdist(\n",
    "                       similarity.matrix[:, sampled_items].T,\n",
    "                       metric='cosine')))\n",
    "            diam_uni = diameter_0(nb_points,similarity.matrix, uniform_items)\n",
    "            diam_dpp = diameter_0(nb_points, similarity.matrix, sampled_items)\n",
    "\n",
    "            sum_det_uni += det_uni\n",
    "            sum_diam_uni += diam_uni\n",
    "            print(diam_uni)\n",
    "            sum_det_dpp += det_dpp\n",
    "            sum_diam_dpp += diam_dpp\n",
    "            #results_uniform.append([det_uni, diam_uni])\n",
    "            #results_sample_dpp.append([det_dpp, diam_dpp])\n",
    "        else:\n",
    "            pb = 0\n",
    "    #print(\"%s \\n %s\" % (results_uniform, results_sample_dpp)) \n",
    "    average_det_uni = sum_det_uni / nb_iterations\n",
    "    average_diam_uni = sum_diam_uni / nb_iterations\n",
    "    average_det_dpp = sum_det_dpp / nb_iterations\n",
    "    average_diam_dpp = sum_diam_dpp / nb_iterations\n",
    "    return average_det_uni, average_diam_uni, average_det_dpp, average_diam_dpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity = SimilarityMatrix()\n",
    "nb_points = 10\n",
    "nb_iterations = 10\n",
    "dpp = MangakiDPP()\n",
    "uniform = MangakiUniform()\n",
    "algos = [dpp, uniform]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voisin/mangaki/venv/lib/python3.4/site-packages/ipykernel/__main__.py:29: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 4271 but corresponding boolean dimension is 182\n",
      "\n",
      "/home/voisin/mangaki/venv/lib/python3.4/site-packages/ipykernel/__main__.py:30: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 1; dimension is 4271 but corresponding boolean dimension is 182\n",
      "\n",
      "/home/voisin/mangaki/venv/lib/python3.4/site-packages/ipykernel/__main__.py:34: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 4271 but corresponding boolean dimension is 182\n",
      "\n",
      "/home/voisin/mangaki/venv/lib/python3.4/site-packages/ipykernel/__main__.py:38: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 4271 but corresponding boolean dimension is 182\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.67768637963\n",
      "2.8328665295\n",
      "5.08394593033\n",
      "3.17672700883\n",
      "4.07049304838\n",
      "3.92364758996\n",
      "3.39913440285\n",
      "0.0\n",
      "0.0\n",
      "2.73362067035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.54472294717685998,\n",
       " 2.889812155981994,\n",
       " -0.83962612045581919,\n",
       " 3.6319515965778493)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare2(similarity, algos, nb_points, nb_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare3(similarity_matrix, algos, nb_points, nb_iterations=100):\n",
    "    liste_sum=[]\n",
    "    \n",
    "    similarity = SimilarityMatrix()\n",
    "    indicateur = 0\n",
    "    pb = 0\n",
    "    \n",
    "\n",
    "    while indicateur != nb_iterations:\n",
    "        try:\n",
    "            sampled_items = dpp.sample_k(similarity, nb_points)\n",
    "        except np.linalg.linalg.LinAlgError as err:\n",
    "            pb = 1\n",
    "        if pb == 0:\n",
    "            indicateur = indicateur+1\n",
    "            uniform_items = uniform.sample_k(list(similarity.user_set),\n",
    "                                             similarity)\n",
    "            det_uni = np.linalg.det(squareform(pdist(\n",
    "                       similarity.matrix[:, uniform_items].T,\n",
    "                       metric='cosine')))\n",
    "            det_dpp = np.linalg.det(squareform(pdist(\n",
    "                       similarity.matrix[:, sampled_items].T,\n",
    "                       metric='cosine')))\n",
    "            diam_uni = diameter_0(nb_points, uniform_items)\n",
    "            diam_dpp = diameter_0(nb_points, sampled_items)\n",
    "\n",
    "            sum_det_uni += det_uni\n",
    "            sum_diam_uni += diam_uni\n",
    "            sum_det_dpp += det_dpp\n",
    "            sum_diam_dpp += diam_dpp\n",
    "            #results_uniform.append([det_uni, diam_uni])\n",
    "            #results_sample_dpp.append([det_dpp, diam_dpp])\n",
    "        else:\n",
    "            pb = 0\n",
    "    #print(\"%s \\n %s\" % (results_uniform, results_sample_dpp)) \n",
    "    average_det_uni = sum_det_uni / nb_iterations\n",
    "    average_diam_uni = sum_diam_uni / nb_iterations\n",
    "    average_det_dpp = sum_det_dpp / nb_iterations\n",
    "    average_diam_dpp = sum_diam_dpp / nb_iterations\n",
    "    return average_det_uni, average_diam_uni, average_det_dpp, average_diam_dpp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
