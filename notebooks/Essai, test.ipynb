{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO note à moi-même : regarder les fonctions compare.py qui existent déjà ds mangaki\n",
    "#revoir ce qu'est pdist et cdist; les différences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test pr 20 éléments (prendre pê moins que 70 pr rg matrice svd car tourne longtemps \n",
    "#mais moins de chance de tomber sur une singular matrix....)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing M: (1710 × 8347)\n",
      "fill and center matrix [892 ms]\n"
     ]
    }
   ],
   "source": [
    "from mangaki.utils.svd import MangakiSVD\n",
    "import numpy as np\n",
    "import pandas \n",
    "from mangaki.utils.values import rating_values\n",
    "from math import sqrt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import random\n",
    "\n",
    "#param : taille rang svd\n",
    "rang_svd=70\n",
    "\n",
    "ratings = pandas.read_csv('../data/ratings.csv', header=None).as_matrix()\n",
    "works=pandas.read_csv('../data/works.csv', header=None).as_matrix()\n",
    "svd =MangakiSVD(rang_svd)\n",
    "X=ratings[:,0:2]\n",
    "Y=[rating_values[rating] for rating in ratings[:,2]]\n",
    "nb_users=X[:,0].max()+1\n",
    "nb_items=X[:,1].max()+1\n",
    "svd.set_parameters(nb_users,nb_items)\n",
    "svd.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copie_SVD=svd.VT.copy()\n",
    "#####################################\n",
    "####################################\n",
    "####################################\n",
    "nb_points=20\n",
    "#requiert une matrice SVD nommée SVD\n",
    "#retourne une matrice de similarité similarity\n",
    "\n",
    "def compute_similarity_coisine(SVD):\n",
    "    nb_items = np.shape(SVD)[1]\n",
    "    J = SVD.T.dot(SVD)\n",
    "    D = np.sqrt(np.diag(J))\n",
    "    similarity = J / D[:,np.newaxis].dot(D[np.newaxis,:])\n",
    "    \n",
    "    \n",
    "    return similarity\n",
    "\n",
    "similarity=compute_similarity_coisine(svd.VT)\n",
    "\n",
    "\n",
    "#######################################\n",
    "#####################################\n",
    "#####################################\n",
    "\n",
    "def sample_k(items, L, k, max_nb_iterations=1000, rng=np.random):\n",
    "    \"\"\"\n",
    "    Sample a list of k items from a DPP defined\n",
    "    by the similarity matrix L. The algorithm\n",
    "    is iterative and runs for max_nb_iterations.\n",
    "    The algorithm used is from\n",
    "    (Fast Determinantal Point Process Sampling withw\n",
    "    Application to Clustering, Byungkon Kang, NIPS 2013)\n",
    "    \"\"\"\n",
    "    initial = rng.choice(range(len(items)), size=k, replace=False)\n",
    "    X = [False] * len(items)\n",
    "    for i in initial:\n",
    "        X[i] = True\n",
    "    X = np.array(X)\n",
    "    for i in range(max_nb_iterations):\n",
    "        u = rng.choice(np.arange(len(items))[X])\n",
    "        v = rng.choice(np.arange(len(items))[~X])\n",
    "        Y = X.copy()\n",
    "        Y[u] = False\n",
    "        L_Y = L[Y, :]\n",
    "        L_Y = L_Y[:, Y]\n",
    "        L_Y_inv = np.linalg.inv(L_Y)\n",
    "\n",
    "        c_v = L[v:v+1, :]\n",
    "        c_v = c_v[:, v:v+1]\n",
    "        b_v = L[Y, :]\n",
    "        b_v = b_v[:, v:v+1]\n",
    "        c_u = L[u:u+1, :]\n",
    "        c_u = c_u[:, u:u+1]\n",
    "        b_u = L[Y, :]\n",
    "        b_u = b_u[:, u:u+1]\n",
    "\n",
    "        p = min(1, c_v - np.dot(np.dot(b_v.T, L_Y_inv), b_v) /\n",
    "                (c_u - np.dot(np.dot(b_u.T, L_Y_inv.T), b_u)))\n",
    "        if rng.uniform() <= p:\n",
    "            X = Y[:]\n",
    "            X[v] = True\n",
    "    return np.array(items)[X] \n",
    "\n",
    "\n",
    "###############################################\n",
    "###############################################\n",
    "###############################################\n",
    "\n",
    "#liste de 10 éléments choisis en utilisant la dpp\n",
    "items = range(0,nb_items)\n",
    "sampled_items = sample_k(items, similarity, nb_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#liste de 10 éléments choisis aléatoirement\n",
    "import random\n",
    "\n",
    "uniform_items = list(range(similarity.shape[0]))\n",
    "random.shuffle(uniform_items)\n",
    "uniform_items = uniform_items[:nb_points]\n",
    "\n",
    "\n",
    "#comparaison de la somme obtenue des distances\n",
    "\n",
    "(pdist(svd.VT[:,sampled_items].T)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniform_items \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pdist(svd.VT[:,uniform_items].T)).sum()\n",
    "#sample\n",
    "#uniforms\n",
    "#compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.clf()\n",
    "plt.plot(svd.VT[0, sampled_items], svd.VT[1, sampled_items], '+b')\n",
    "plt.plot(svd.VT[0, uniform_items]+0.8, svd.VT[1, uniform_items], '+g')\n",
    "# ! translation des pts choisis aléatoirement pr miexu voir les clusters, illisible graphiquement sinon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.text(0, 0.02, 'avec DPP')\n",
    "plt.text(0.6, 0.02, 'sans DPP (aléatoire)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#autre test : faire une moyenne de plusieurs tests successifs\n",
    "#ne marche pas : toujours pas de chance : une singular_matrix apparait\n",
    "#il serait peut-être bien de vérifier que la matrice est inversible ou alors utiliser ratings directement au lieu de svd.VT\n",
    "# iteration=0\n",
    "#tant que iteration !=10, si similarity inversible (utiliser sample_k et iteration++)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mangaki.utils.svd import MangakiSVD\n",
    "import numpy as np\n",
    "import pandas \n",
    "from mangaki.utils.values import rating_values\n",
    "from math import sqrt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import random\n",
    "\n",
    "#param : taille rang svd\n",
    "rang_svd=20\n",
    "\n",
    "ratings = pandas.read_csv('../data/ratings.csv', header=None).as_matrix()\n",
    "works=pandas.read_csv('../data/works.csv', header=None).as_matrix()\n",
    "\n",
    "X=ratings[:,0:2]\n",
    "Y=[rating_values[rating] for rating in ratings[:,2]]\n",
    "nb_users=X[:,0].max()+1\n",
    "nb_items=X[:,1].max()+1\n",
    "svd =MangakiSVD(rang_svd)\n",
    "svd.set_parameters(nb_users,nb_items)\n",
    "svd.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################\n",
    "####################################\n",
    "####################################\n",
    "nb_points=10\n",
    "#requiert une matrice SVD nommée SVD\n",
    "#retourne une matrice de similarité similarity\n",
    "\n",
    "def compute_similarity_coisine(SVD):\n",
    "    nb_items = np.shape(SVD)[1]\n",
    "    J = SVD.T.dot(SVD)\n",
    "    D = np.sqrt(np.diag(J))\n",
    "    similarity = J / D[:,np.newaxis].dot(D[np.newaxis,:])\n",
    "    \n",
    "    \n",
    "    return similarity\n",
    "\n",
    "similarity=compute_similarity_coisine(svd.VT)\n",
    "\n",
    "\n",
    "#######################################\n",
    "#####################################\n",
    "#####################################\n",
    "\n",
    "def sample_k(items, L, k, max_nb_iterations=1000, rng=np.random):\n",
    "    \"\"\"\n",
    "    Sample a list of k items from a DPP defined\n",
    "    by the similarity matrix L. The algorithm\n",
    "    is iterative and runs for max_nb_iterations.\n",
    "    The algorithm used is from\n",
    "    (Fast Determinantal Point Process Sampling withw\n",
    "    Application to Clustering, Byungkon Kang, NIPS 2013)\n",
    "    \"\"\"\n",
    "    initial = rng.choice(range(len(items)), size=k, replace=False)\n",
    "    X = [False] * len(items)\n",
    "    for i in initial:\n",
    "        X[i] = True\n",
    "    X = np.array(X)\n",
    "    for i in range(max_nb_iterations):\n",
    "        u = rng.choice(np.arange(len(items))[X])\n",
    "        v = rng.choice(np.arange(len(items))[~X])\n",
    "        Y = X.copy()\n",
    "        Y[u] = False\n",
    "        L_Y = L[Y, :]\n",
    "        L_Y = L_Y[:, Y]\n",
    "        L_Y_inv = np.linalg.inv(L_Y)\n",
    "\n",
    "        c_v = L[v:v+1, :]\n",
    "        c_v = c_v[:, v:v+1]\n",
    "        b_v = L[Y, :]\n",
    "        b_v = b_v[:, v:v+1]\n",
    "        c_u = L[u:u+1, :]\n",
    "        c_u = c_u[:, u:u+1]\n",
    "        b_u = L[Y, :]\n",
    "        b_u = b_u[:, u:u+1]\n",
    "\n",
    "        p = min(1, c_v - np.dot(np.dot(b_v.T, L_Y_inv), b_v) /\n",
    "                (c_u - np.dot(np.dot(b_u.T, L_Y_inv.T), b_u)))\n",
    "        if rng.uniform() <= p:\n",
    "            X = Y[:]\n",
    "            X[v] = True\n",
    "    return np.array(items)[X] \n",
    "\n",
    "\n",
    "###############################################\n",
    "###############################################\n",
    "###############################################\n",
    "\n",
    "#liste de 10 éléments choisis en utilisant la dpp\n",
    "items = range(0,nb_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#liste de 10 éléments choisis aléatoirement\n",
    "\n",
    "uniform_items = list(range(similarity.shape[0]))\n",
    "distance_sample=[]\n",
    "distance_uniform=[]\n",
    "for i in range(10):\n",
    "    sampled_items = sample_k(items, similarity, nb_points)\n",
    "    random.shuffle(uniform_items)\n",
    "    uniform_items = uniform_items[:nb_points]\n",
    "\n",
    "\n",
    "#comparaison de la somme obtenue des distances\n",
    "\n",
    "    distance_sample.append((pdist(svd.VT[:,sampled_items].T)).sum())\n",
    "    distance_uniform.append((pdist(svd.VT[:,uniform_items].T)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dispersion statistique : diamètre d'ordre r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Utilisation de diamètre :   \n",
    "#https://fr.wikipedia.org/wiki/Dispersion_statistique\n",
    "#https://msh.revues.org/3553?file=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "essai, exemple : diamètre d'ordre 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uniform_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nb_points est défini\n",
    "#pdist(X, euclidian), cdist ? \n",
    "\n",
    "\n",
    "distance_sample = squareform(pdist(svd.VT[:,sampled_items].T))\n",
    "distance_uniform = squareform(pdist(svd.VT[:,uniform_items].T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#en cours de confection\n",
    "n=len(sampled_items)\n",
    "cefficient_D1=2/(n*(n-1))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
